{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "sns.set(style=\"white\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"development_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAR1       int64\n",
       "VAR2     float64\n",
       "VAR3     float64\n",
       "VAR4     float64\n",
       "VAR5     float64\n",
       "VAR6     float64\n",
       "VAR7     float64\n",
       "VAR8     float64\n",
       "VAR9     float64\n",
       "VAR10    float64\n",
       "VAR11    float64\n",
       "VAR12    float64\n",
       "VAR13    float64\n",
       "VAR14     object\n",
       "VAR15    float64\n",
       "VAR16    float64\n",
       "VAR17    float64\n",
       "VAR18      int64\n",
       "VAR19      int64\n",
       "VAR20    float64\n",
       "VAR21     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data)\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR1</th>\n",
       "      <th>VAR2</th>\n",
       "      <th>VAR3</th>\n",
       "      <th>VAR4</th>\n",
       "      <th>VAR5</th>\n",
       "      <th>VAR6</th>\n",
       "      <th>VAR7</th>\n",
       "      <th>VAR8</th>\n",
       "      <th>VAR9</th>\n",
       "      <th>VAR10</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR12</th>\n",
       "      <th>VAR13</th>\n",
       "      <th>VAR14</th>\n",
       "      <th>VAR15</th>\n",
       "      <th>VAR16</th>\n",
       "      <th>VAR17</th>\n",
       "      <th>VAR18</th>\n",
       "      <th>VAR19</th>\n",
       "      <th>VAR20</th>\n",
       "      <th>VAR21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>828.235294</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>321.428571</td>\n",
       "      <td>625.911006</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>1.081550</td>\n",
       "      <td>198.113469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>100.083403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.540594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.104991</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>911.764706</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>611.574748</td>\n",
       "      <td>8.181818</td>\n",
       "      <td>1.344479</td>\n",
       "      <td>198.600020</td>\n",
       "      <td>22.086661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.012510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.614613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>146.654045</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>962.352941</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>35.714286</td>\n",
       "      <td>615.825381</td>\n",
       "      <td>8.181818</td>\n",
       "      <td>0.720796</td>\n",
       "      <td>197.267767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>210.175146</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.044599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.249570</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>892.941177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>638.076431</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>0.820218</td>\n",
       "      <td>197.355744</td>\n",
       "      <td>4.363431</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.145729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140.862306</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>914.117647</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>626.514988</td>\n",
       "      <td>5.181818</td>\n",
       "      <td>1.372928</td>\n",
       "      <td>198.790477</td>\n",
       "      <td>85.938202</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>210.175146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.558341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.268503</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VAR1        VAR2      VAR3        VAR4        VAR5      VAR6      VAR7  \\\n",
       "0     1  828.235294  0.138889  321.428571  625.911006  1.818182  1.081550   \n",
       "1     2  911.764706  0.027778         NaN  611.574748  8.181818  1.344479   \n",
       "2     3  962.352941  0.833333   35.714286  615.825381  8.181818  0.720796   \n",
       "3     4  892.941177       NaN         NaN  638.076431  9.090909  0.820218   \n",
       "4     5  914.117647  0.083333         NaN  626.514988  5.181818  1.372928   \n",
       "\n",
       "         VAR8       VAR9      VAR10   ...         VAR12  VAR13  VAR14 VAR15  \\\n",
       "0  198.113469        NaN  58.632548   ...    100.083403    1.0      1   1.0   \n",
       "1  198.600020  22.086661        NaN   ...     15.012510    NaN      1   NaN   \n",
       "2  197.267767        NaN  58.632548   ...    210.175146   10.0      1  10.0   \n",
       "3  197.355744   4.363431  58.632548   ...           NaN    NaN      1   NaN   \n",
       "4  198.790477  85.938202  58.632548   ...    210.175146    NaN      .   NaN   \n",
       "\n",
       "      VAR16  VAR17  VAR18  VAR19       VAR20   VAR21  \n",
       "0  1.540594    NaN      1      0  100.104991     Low  \n",
       "1  1.614613    NaN      0      1  146.654045    High  \n",
       "2  1.044599    NaN      0      0   98.249570  Medium  \n",
       "3  1.145729    NaN      1      0  140.862306     Low  \n",
       "4  1.558341    NaN      1      0  101.268503    High  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR1</th>\n",
       "      <th>VAR2</th>\n",
       "      <th>VAR3</th>\n",
       "      <th>VAR4</th>\n",
       "      <th>VAR5</th>\n",
       "      <th>VAR6</th>\n",
       "      <th>VAR7</th>\n",
       "      <th>VAR8</th>\n",
       "      <th>VAR9</th>\n",
       "      <th>VAR10</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR12</th>\n",
       "      <th>VAR13</th>\n",
       "      <th>VAR14</th>\n",
       "      <th>VAR15</th>\n",
       "      <th>VAR16</th>\n",
       "      <th>VAR17</th>\n",
       "      <th>VAR18</th>\n",
       "      <th>VAR19</th>\n",
       "      <th>VAR20</th>\n",
       "      <th>VAR21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>828.235294</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>321.428571</td>\n",
       "      <td>625.911006</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>1.081550</td>\n",
       "      <td>198.113469</td>\n",
       "      <td>53.988554</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>100.083403</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.540594</td>\n",
       "      <td>821.281092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.104991</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>911.764706</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>248.076201</td>\n",
       "      <td>611.574748</td>\n",
       "      <td>8.181818</td>\n",
       "      <td>1.344479</td>\n",
       "      <td>198.600020</td>\n",
       "      <td>22.086661</td>\n",
       "      <td>56.497320</td>\n",
       "      <td>...</td>\n",
       "      <td>15.012510</td>\n",
       "      <td>11.679589</td>\n",
       "      <td>1</td>\n",
       "      <td>12.453257</td>\n",
       "      <td>1.614613</td>\n",
       "      <td>821.281092</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>146.654045</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>962.352941</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>35.714286</td>\n",
       "      <td>615.825381</td>\n",
       "      <td>8.181818</td>\n",
       "      <td>0.720796</td>\n",
       "      <td>197.267767</td>\n",
       "      <td>53.988554</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>210.175146</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.044599</td>\n",
       "      <td>821.281092</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.249570</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>892.941177</td>\n",
       "      <td>1.119596</td>\n",
       "      <td>248.076201</td>\n",
       "      <td>638.076431</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>0.820218</td>\n",
       "      <td>197.355744</td>\n",
       "      <td>4.363431</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>117.283667</td>\n",
       "      <td>11.679589</td>\n",
       "      <td>1</td>\n",
       "      <td>12.453257</td>\n",
       "      <td>1.145729</td>\n",
       "      <td>821.281092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140.862306</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>914.117647</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>248.076201</td>\n",
       "      <td>626.514988</td>\n",
       "      <td>5.181818</td>\n",
       "      <td>1.372928</td>\n",
       "      <td>198.790477</td>\n",
       "      <td>85.938202</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>210.175146</td>\n",
       "      <td>11.679589</td>\n",
       "      <td>.</td>\n",
       "      <td>12.453257</td>\n",
       "      <td>1.558341</td>\n",
       "      <td>821.281092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>101.268503</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VAR1        VAR2      VAR3        VAR4        VAR5      VAR6      VAR7  \\\n",
       "0     1  828.235294  0.138889  321.428571  625.911006  1.818182  1.081550   \n",
       "1     2  911.764706  0.027778  248.076201  611.574748  8.181818  1.344479   \n",
       "2     3  962.352941  0.833333   35.714286  615.825381  8.181818  0.720796   \n",
       "3     4  892.941177  1.119596  248.076201  638.076431  9.090909  0.820218   \n",
       "4     5  914.117647  0.083333  248.076201  626.514988  5.181818  1.372928   \n",
       "\n",
       "         VAR8       VAR9      VAR10   ...         VAR12      VAR13  VAR14  \\\n",
       "0  198.113469  53.988554  58.632548   ...    100.083403   1.000000      1   \n",
       "1  198.600020  22.086661  56.497320   ...     15.012510  11.679589      1   \n",
       "2  197.267767  53.988554  58.632548   ...    210.175146  10.000000      1   \n",
       "3  197.355744   4.363431  58.632548   ...    117.283667  11.679589      1   \n",
       "4  198.790477  85.938202  58.632548   ...    210.175146  11.679589      .   \n",
       "\n",
       "       VAR15     VAR16       VAR17  VAR18  VAR19       VAR20   VAR21  \n",
       "0   1.000000  1.540594  821.281092      1      0  100.104991     Low  \n",
       "1  12.453257  1.614613  821.281092      0      1  146.654045    High  \n",
       "2  10.000000  1.044599  821.281092      0      0   98.249570  Medium  \n",
       "3  12.453257  1.145729  821.281092      1      0  140.862306     Low  \n",
       "4  12.453257  1.558341  821.281092      1      0  101.268503    High  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.fillna(data.mean())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAR1       int64\n",
       "VAR2     float64\n",
       "VAR3     float64\n",
       "VAR4     float64\n",
       "VAR5     float64\n",
       "VAR6     float64\n",
       "VAR7     float64\n",
       "VAR8     float64\n",
       "VAR9     float64\n",
       "VAR10    float64\n",
       "VAR11    float64\n",
       "VAR12    float64\n",
       "VAR13    float64\n",
       "VAR14      int64\n",
       "VAR15    float64\n",
       "VAR16    float64\n",
       "VAR17    float64\n",
       "VAR18      int64\n",
       "VAR19      int64\n",
       "VAR20    float64\n",
       "VAR21      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "le = LabelEncoder()\n",
    "data[\"VAR21\"] = le.fit_transform(data[\"VAR21\"])\n",
    "data[\"VAR14\"] = le.fit_transform(data[\"VAR14\"])\n",
    "\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(np.abs(stats.zscore(data)) < 2.8).all(axis=1)]\n",
    "data[\"VAR1\"] = data[\"VAR1\"].interpolate()\n",
    "data[\"VAR2\"] = data[\"VAR2\"].interpolate()\n",
    "data[\"VAR3\"] = data[\"VAR3\"].interpolate()\n",
    "data[\"VAR4\"] = data[\"VAR4\"].interpolate()\n",
    "data[\"VAR5\"] = data[\"VAR5\"].interpolate()\n",
    "data[\"VAR6\"] = data[\"VAR6\"].interpolate()\n",
    "data[\"VAR7\"] = data[\"VAR7\"].interpolate()\n",
    "data[\"VAR8\"] = data[\"VAR8\"].interpolate()\n",
    "data[\"VAR9\"] = data[\"VAR9\"].interpolate()\n",
    "data[\"VAR10\"] = data[\"VAR10\"].interpolate()\n",
    "data[\"VAR11\"] = data[\"VAR11\"].interpolate()\n",
    "data[\"VAR12\"] = data[\"VAR12\"].interpolate()\n",
    "data[\"VAR13\"] = data[\"VAR13\"].interpolate()\n",
    "data[\"VAR14\"] = data[\"VAR14\"].interpolate()\n",
    "data[\"VAR15\"] = data[\"VAR15\"].interpolate()\n",
    "data[\"VAR16\"] = data[\"VAR16\"].interpolate()\n",
    "data[\"VAR17\"] = data[\"VAR17\"].interpolate()\n",
    "data[\"VAR18\"] = data[\"VAR18\"].interpolate()\n",
    "data[\"VAR19\"] = data[\"VAR19\"].interpolate()\n",
    "data[\"VAR20\"] = data[\"VAR20\"].interpolate()\n",
    "data[\"VAR21\"] = data[\"VAR21\"].interpolate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR1</th>\n",
       "      <th>VAR2</th>\n",
       "      <th>VAR3</th>\n",
       "      <th>VAR4</th>\n",
       "      <th>VAR5</th>\n",
       "      <th>VAR6</th>\n",
       "      <th>VAR7</th>\n",
       "      <th>VAR8</th>\n",
       "      <th>VAR9</th>\n",
       "      <th>VAR10</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR12</th>\n",
       "      <th>VAR13</th>\n",
       "      <th>VAR14</th>\n",
       "      <th>VAR15</th>\n",
       "      <th>VAR16</th>\n",
       "      <th>VAR17</th>\n",
       "      <th>VAR18</th>\n",
       "      <th>VAR19</th>\n",
       "      <th>VAR20</th>\n",
       "      <th>VAR21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>828.235294</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>321.428571</td>\n",
       "      <td>625.911006</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>1.081550</td>\n",
       "      <td>198.113469</td>\n",
       "      <td>53.988554</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>100.083403</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.540594</td>\n",
       "      <td>821.281092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.104991</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>911.764706</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>248.076201</td>\n",
       "      <td>611.574748</td>\n",
       "      <td>8.181818</td>\n",
       "      <td>1.344479</td>\n",
       "      <td>198.600020</td>\n",
       "      <td>22.086661</td>\n",
       "      <td>56.497320</td>\n",
       "      <td>...</td>\n",
       "      <td>15.012510</td>\n",
       "      <td>11.679589</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.453257</td>\n",
       "      <td>1.614613</td>\n",
       "      <td>821.281092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>146.654045</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>962.352941</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>35.714286</td>\n",
       "      <td>615.825381</td>\n",
       "      <td>8.181818</td>\n",
       "      <td>0.720796</td>\n",
       "      <td>197.267767</td>\n",
       "      <td>53.988554</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>210.175146</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.044599</td>\n",
       "      <td>821.281092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.249570</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>892.941177</td>\n",
       "      <td>1.119596</td>\n",
       "      <td>248.076201</td>\n",
       "      <td>638.076431</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>0.820218</td>\n",
       "      <td>197.355744</td>\n",
       "      <td>4.363431</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>117.283667</td>\n",
       "      <td>11.679589</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.453257</td>\n",
       "      <td>1.145729</td>\n",
       "      <td>821.281092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.862306</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>914.117647</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>248.076201</td>\n",
       "      <td>626.514988</td>\n",
       "      <td>5.181818</td>\n",
       "      <td>1.372928</td>\n",
       "      <td>198.790477</td>\n",
       "      <td>85.938202</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>210.175146</td>\n",
       "      <td>11.679589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.453257</td>\n",
       "      <td>1.558341</td>\n",
       "      <td>821.281092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.268503</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VAR1        VAR2      VAR3        VAR4        VAR5      VAR6      VAR7  \\\n",
       "0   1.0  828.235294  0.138889  321.428571  625.911006  1.818182  1.081550   \n",
       "1   2.0  911.764706  0.027778  248.076201  611.574748  8.181818  1.344479   \n",
       "2   3.0  962.352941  0.833333   35.714286  615.825381  8.181818  0.720796   \n",
       "3   4.0  892.941177  1.119596  248.076201  638.076431  9.090909  0.820218   \n",
       "4   5.0  914.117647  0.083333  248.076201  626.514988  5.181818  1.372928   \n",
       "\n",
       "         VAR8       VAR9      VAR10  ...         VAR12      VAR13  VAR14  \\\n",
       "0  198.113469  53.988554  58.632548  ...    100.083403   1.000000    2.0   \n",
       "1  198.600020  22.086661  56.497320  ...     15.012510  11.679589    2.0   \n",
       "2  197.267767  53.988554  58.632548  ...    210.175146  10.000000    2.0   \n",
       "3  197.355744   4.363431  58.632548  ...    117.283667  11.679589    2.0   \n",
       "4  198.790477  85.938202  58.632548  ...    210.175146  11.679589    0.0   \n",
       "\n",
       "       VAR15     VAR16       VAR17  VAR18  VAR19       VAR20  VAR21  \n",
       "0   1.000000  1.540594  821.281092    1.0    0.0  100.104991    1.0  \n",
       "1  12.453257  1.614613  821.281092    0.0    1.0  146.654045    0.0  \n",
       "2  10.000000  1.044599  821.281092    0.0    0.0   98.249570    2.0  \n",
       "3  12.453257  1.145729  821.281092    1.0    0.0  140.862306    1.0  \n",
       "4  12.453257  1.558341  821.281092    1.0    0.0  101.268503    0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x125a95198>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "sns.heatmap(data.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR1</th>\n",
       "      <th>VAR2</th>\n",
       "      <th>VAR3</th>\n",
       "      <th>VAR4</th>\n",
       "      <th>VAR5</th>\n",
       "      <th>VAR6</th>\n",
       "      <th>VAR7</th>\n",
       "      <th>VAR8</th>\n",
       "      <th>VAR9</th>\n",
       "      <th>VAR10</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR12</th>\n",
       "      <th>VAR13</th>\n",
       "      <th>VAR14</th>\n",
       "      <th>VAR15</th>\n",
       "      <th>VAR16</th>\n",
       "      <th>VAR17</th>\n",
       "      <th>VAR18</th>\n",
       "      <th>VAR19</th>\n",
       "      <th>VAR20</th>\n",
       "      <th>VAR21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17000.500000</td>\n",
       "      <td>917.391603</td>\n",
       "      <td>1.119596</td>\n",
       "      <td>248.076201</td>\n",
       "      <td>631.571391</td>\n",
       "      <td>15.290028</td>\n",
       "      <td>2.055295</td>\n",
       "      <td>200.007169</td>\n",
       "      <td>53.988554</td>\n",
       "      <td>56.497320</td>\n",
       "      <td>...</td>\n",
       "      <td>117.283667</td>\n",
       "      <td>11.679589</td>\n",
       "      <td>5.368088</td>\n",
       "      <td>12.453257</td>\n",
       "      <td>2.092006</td>\n",
       "      <td>821.281092</td>\n",
       "      <td>0.400029</td>\n",
       "      <td>0.298059</td>\n",
       "      <td>161.355950</td>\n",
       "      <td>1.424265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9815.098913</td>\n",
       "      <td>49.507520</td>\n",
       "      <td>12.065182</td>\n",
       "      <td>191.803194</td>\n",
       "      <td>30.862834</td>\n",
       "      <td>27.586308</td>\n",
       "      <td>8.850169</td>\n",
       "      <td>11.142819</td>\n",
       "      <td>61.847601</td>\n",
       "      <td>6.385476</td>\n",
       "      <td>...</td>\n",
       "      <td>100.282096</td>\n",
       "      <td>9.577494</td>\n",
       "      <td>4.789902</td>\n",
       "      <td>10.563069</td>\n",
       "      <td>7.948597</td>\n",
       "      <td>154.582927</td>\n",
       "      <td>0.684850</td>\n",
       "      <td>0.457412</td>\n",
       "      <td>123.231136</td>\n",
       "      <td>0.681681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>730.588235</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>18.928571</td>\n",
       "      <td>347.053355</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.353228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>13.028620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834028</td>\n",
       "      <td>0.082667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.959315</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8500.750000</td>\n",
       "      <td>883.529412</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>107.142857</td>\n",
       "      <td>611.691605</td>\n",
       "      <td>6.818182</td>\n",
       "      <td>0.696416</td>\n",
       "      <td>197.209616</td>\n",
       "      <td>22.086661</td>\n",
       "      <td>56.497320</td>\n",
       "      <td>...</td>\n",
       "      <td>40.033361</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>1.044812</td>\n",
       "      <td>821.281092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>104.385542</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17000.500000</td>\n",
       "      <td>922.352941</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>248.076201</td>\n",
       "      <td>619.803785</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>1.019184</td>\n",
       "      <td>197.966296</td>\n",
       "      <td>53.988554</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>117.283667</td>\n",
       "      <td>11.679589</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.453257</td>\n",
       "      <td>1.279816</td>\n",
       "      <td>821.281092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117.493115</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25500.250000</td>\n",
       "      <td>956.470588</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>248.076201</td>\n",
       "      <td>637.448377</td>\n",
       "      <td>16.363636</td>\n",
       "      <td>1.836638</td>\n",
       "      <td>199.917738</td>\n",
       "      <td>53.988554</td>\n",
       "      <td>58.632548</td>\n",
       "      <td>...</td>\n",
       "      <td>130.108424</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>1.908664</td>\n",
       "      <td>821.281092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>159.446213</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>909.090818</td>\n",
       "      <td>681.582083</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>993.061289</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>775.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>775.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               VAR1          VAR2          VAR3          VAR4          VAR5  \\\n",
       "count  34000.000000  34000.000000  34000.000000  34000.000000  34000.000000   \n",
       "mean   17000.500000    917.391603      1.119596    248.076201    631.571391   \n",
       "std     9815.098913     49.507520     12.065182    191.803194     30.862834   \n",
       "min        1.000000    730.588235      0.001333     18.928571    347.053355   \n",
       "25%     8500.750000    883.529412      0.083333    107.142857    611.691605   \n",
       "50%    17000.500000    922.352941      0.200000    248.076201    619.803785   \n",
       "75%    25500.250000    956.470588      0.833333    248.076201    637.448377   \n",
       "max    34000.000000   1000.000000   1000.000000   1000.000000   1000.000000   \n",
       "\n",
       "               VAR6          VAR7          VAR8          VAR9         VAR10  \\\n",
       "count  34000.000000  34000.000000  34000.000000  34000.000000  34000.000000   \n",
       "mean      15.290028      2.055295    200.007169     53.988554     56.497320   \n",
       "std       27.586308      8.850169     11.142819     61.847601      6.385476   \n",
       "min        0.005000      0.353228      0.000000      0.004278     13.028620   \n",
       "25%        6.818182      0.696416    197.209616     22.086661     56.497320   \n",
       "50%       11.363636      1.019184    197.966296     53.988554     58.632548   \n",
       "75%       16.363636      1.836638    199.917738     53.988554     58.632548   \n",
       "max      909.090818    681.582083   1000.000000    993.061289   1000.000000   \n",
       "\n",
       "           ...              VAR12         VAR13         VAR14         VAR15  \\\n",
       "count      ...       34000.000000  34000.000000  34000.000000  34000.000000   \n",
       "mean       ...         117.283667     11.679589      5.368088     12.453257   \n",
       "std        ...         100.282096      9.577494      4.789902     10.563069   \n",
       "min        ...           0.834028      0.082667      0.000000      0.133333   \n",
       "25%        ...          40.033361      6.666667      2.000000      7.333333   \n",
       "50%        ...         117.283667     11.679589      2.000000     12.453257   \n",
       "75%        ...         130.108424     13.333333     10.000000     13.333333   \n",
       "max        ...        1000.000000    775.000000     20.000000    775.000000   \n",
       "\n",
       "              VAR16         VAR17         VAR18         VAR19         VAR20  \\\n",
       "count  34000.000000  34000.000000  34000.000000  34000.000000  34000.000000   \n",
       "mean       2.092006    821.281092      0.400029      0.298059    161.355950   \n",
       "std        7.948597    154.582927      0.684850      0.457412    123.231136   \n",
       "min        0.959315      0.130000      0.000000      0.000000      0.000000   \n",
       "25%        1.044812    821.281092      0.000000      0.000000    104.385542   \n",
       "50%        1.279816    821.281092      0.000000      0.000000    117.493115   \n",
       "75%        1.908664    821.281092      1.000000      1.000000    159.446213   \n",
       "max     1000.000000   1000.000000     14.000000      1.000000   1000.000000   \n",
       "\n",
       "              VAR21  \n",
       "count  34000.000000  \n",
       "mean       1.424265  \n",
       "std        0.681681  \n",
       "min        0.000000  \n",
       "25%        1.000000  \n",
       "50%        2.000000  \n",
       "75%        2.000000  \n",
       "max        2.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data[\"VAR21\"]\n",
    "X = data.drop([\"VAR21\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ElasticNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "model = ElasticNetCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.0118109 , 0.01115137, 0.0079568 ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(model, X, y, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\u001b[0m\n",
      "Requirement already satisfied: wheel in /Users/youknowwho/anaconda2/lib/python2.7/site-packages (0.29.0)\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7.\u001b[0m\n",
      "Collecting lightgbm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/83/6e4a9cc870c117bf8316e8aa2513c5070f9ae2f8bd69469476414cd42595/lightgbm-2.3.0-py2.py3-none-macosx_10_8_x86_64.macosx_10_9_x86_64.macosx_10_10_x86_64.macosx_10_11_x86_64.macosx_10_12_x86_64.macosx_10_13_x86_64.macosx_10_14_x86_64.whl (678kB)\n",
      "\u001b[K    100% |████████████████████████████████| 686kB 1.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /Users/youknowwho/anaconda2/lib/python2.7/site-packages (from lightgbm) (0.20.1)\n",
      "Requirement already satisfied: scipy in /Users/youknowwho/anaconda2/lib/python2.7/site-packages (from lightgbm) (0.19.1)\n",
      "Requirement already satisfied: numpy in /Users/youknowwho/anaconda2/lib/python2.7/site-packages (from lightgbm) (1.13.3)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-2.3.0\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wheel\n",
    "!pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-fc932285b307>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLGBMRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLGBMRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboosting_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gbdt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_leaves\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m675\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_bin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample_for_bin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_split_gain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_child_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_child_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.995\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolsample_bytree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/lightgbm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from .callback import (early_stopping, print_evaluation, record_evaluation,\n\u001b[1;32m     10\u001b[0m                        reset_parameter)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "model = LGBMRegressor(boosting_type='gbdt', num_leaves=10, max_depth=4, learning_rate=0.005, n_estimators=675, max_bin=25, subsample_for_bin=50000, objective=None, min_split_gain=0, min_child_weight=5, min_child_samples=10, subsample=0.995, subsample_freq=1, colsample_bytree=1, reg_alpha=0, reg_lambda=0, seed=0, nthread=-1, silent=True)\n",
    "cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vrishank/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.13562921, 0.40613674, 0.14828642, 0.18372499, 0.00737995,\n",
       "       0.11160144, 0.00292036, 0.0043209 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0, n_estimators=100)\n",
    "regr.fit(X, y)\n",
    "regr.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Feature Importances from Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAAI+CAYAAADNU9EfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1200f4d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(np.arange(len(regr.feature_importances_)), regr.feature_importances_)\n",
    "plt.xticks(np.arange(len(regr.feature_importances_)), X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Columns that are less important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, j in zip(regr.feature_importances_, X.columns):\n",
    "    if i<0.05:\n",
    "        data = data.drop(j, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7350357 , 0.83311671, 0.2416629 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor(boosting_type='gbdt', num_leaves=10, max_depth=5, learning_rate=0.005, n_estimators=675, max_bin=25, subsample_for_bin=50000, objective=None, min_split_gain=0, min_child_weight=5, min_child_samples=10, subsample=0.995, subsample_freq=1, colsample_bytree=1, reg_alpha=0, reg_lambda=0, seed=0, nthread=-1, silent=True)\n",
    "cross_val_score(model, X, y, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV] max_depth=2, n_estimators=100 ...................................\n",
      "[CV]  max_depth=2, n_estimators=100, score=-0.063199654182859, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=100 ...................................\n",
      "[CV]  max_depth=2, n_estimators=100, score=0.09352502087074309, total=   0.1s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=100 ...................................\n",
      "[CV]  max_depth=2, n_estimators=100, score=0.4551676065747966, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.5s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=100 ...................................\n",
      "[CV]  max_depth=2, n_estimators=100, score=0.42588211486545224, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.7s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=100 ...................................\n",
      "[CV]  max_depth=2, n_estimators=100, score=-1.7922607755423092, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=300 ...................................\n",
      "[CV]  max_depth=2, n_estimators=300, score=0.6162235465790127, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.2s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=300 ...................................\n",
      "[CV]  max_depth=2, n_estimators=300, score=0.638707262675934, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    1.6s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=300 ...................................\n",
      "[CV]  max_depth=2, n_estimators=300, score=0.8129300804400068, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    1.9s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=300 ...................................\n",
      "[CV]  max_depth=2, n_estimators=300, score=0.7513298282624602, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    2.2s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=300 ...................................\n",
      "[CV]  max_depth=2, n_estimators=300, score=-0.4386312109496386, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.6s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=500 ...................................\n",
      "[CV]  max_depth=2, n_estimators=500, score=0.8094734640907564, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    3.1s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=500 ...................................\n",
      "[CV]  max_depth=2, n_estimators=500, score=0.7839577099171772, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    3.7s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=500 ...................................\n",
      "[CV]  max_depth=2, n_estimators=500, score=0.864968402006055, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    4.2s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=500 ...................................\n",
      "[CV]  max_depth=2, n_estimators=500, score=0.8123767974247357, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    4.7s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=500 ...................................\n",
      "[CV]  max_depth=2, n_estimators=500, score=0.042955968217883944, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    5.2s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=700 ...................................\n",
      "[CV]  max_depth=2, n_estimators=700, score=0.8551968676093183, total=   0.7s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    5.9s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=700 ...................................\n",
      "[CV]  max_depth=2, n_estimators=700, score=0.8295545960753443, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    6.6s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=700 ...................................\n",
      "[CV]  max_depth=2, n_estimators=700, score=0.8730748754495321, total=   0.7s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    7.3s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=700 ...................................\n",
      "[CV]  max_depth=2, n_estimators=700, score=0.8262685800085317, total=   0.7s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    7.9s remaining:    0.0s\n",
      "[CV] max_depth=2, n_estimators=700 ...................................\n",
      "[CV]  max_depth=2, n_estimators=700, score=0.22186539583193873, total=   0.7s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    8.6s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV]  max_depth=3, n_estimators=100, score=0.05931270264777189, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    8.8s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV]  max_depth=3, n_estimators=100, score=0.17621362937755458, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    9.0s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV]  max_depth=3, n_estimators=100, score=0.4626405767836389, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:    9.2s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV]  max_depth=3, n_estimators=100, score=0.47536630915479294, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    9.3s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV]  max_depth=3, n_estimators=100, score=-1.3310337476508294, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    9.5s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=300 ...................................\n",
      "[CV]  max_depth=3, n_estimators=300, score=0.7357387767511432, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:   10.0s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=300 ...................................\n",
      "[CV]  max_depth=3, n_estimators=300, score=0.7213111513350956, total=   0.4s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   10.4s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=300 ...................................\n",
      "[CV]  max_depth=3, n_estimators=300, score=0.8008585471722176, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:   10.9s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=300 ...................................\n",
      "[CV]  max_depth=3, n_estimators=300, score=0.7488688876338114, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:   11.4s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=300 ...................................\n",
      "[CV]  max_depth=3, n_estimators=300, score=-0.09501278116241131, total=   0.5s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   11.9s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=500 ...................................\n",
      "[CV]  max_depth=3, n_estimators=500, score=0.8460007444381445, total=   0.8s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:   12.7s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=500 ...................................\n",
      "[CV]  max_depth=3, n_estimators=500, score=0.820682749842448, total=   0.8s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:   13.5s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=500 ...................................\n",
      "[CV]  max_depth=3, n_estimators=500, score=0.8551668142662529, total=   0.8s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:   14.3s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=500 ...................................\n",
      "[CV]  max_depth=3, n_estimators=500, score=0.7965582249821468, total=   0.8s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:   15.1s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=500 ...................................\n",
      "[CV]  max_depth=3, n_estimators=500, score=0.20630059234384424, total=   0.8s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:   15.9s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=700 ...................................\n",
      "[CV]  max_depth=3, n_estimators=700, score=0.8617347217342463, total=   1.1s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:   17.0s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=700 ...................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=3, n_estimators=700, score=0.8461093215580775, total=   1.2s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:   18.2s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=700 ...................................\n",
      "[CV]  max_depth=3, n_estimators=700, score=0.8608892381266792, total=   1.2s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:   19.4s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=700 ...................................\n",
      "[CV]  max_depth=3, n_estimators=700, score=0.8022498076232154, total=   1.1s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:   20.5s remaining:    0.0s\n",
      "[CV] max_depth=3, n_estimators=700 ...................................\n",
      "[CV]  max_depth=3, n_estimators=700, score=0.33686344785286704, total=   1.1s\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:   21.6s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n",
      "[CV]  max_depth=4, n_estimators=100, score=0.09793850878361143, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:   21.9s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n",
      "[CV]  max_depth=4, n_estimators=100, score=0.1945400441589401, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:   22.1s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n",
      "[CV]  max_depth=4, n_estimators=100, score=0.47133437436669173, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:   22.3s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n",
      "[CV]  max_depth=4, n_estimators=100, score=0.5103274753030873, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed:   22.5s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n",
      "[CV]  max_depth=4, n_estimators=100, score=-1.355331299879031, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   22.8s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=300 ...................................\n",
      "[CV]  max_depth=4, n_estimators=300, score=0.7478638934415873, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed:   23.4s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=300 ...................................\n",
      "[CV]  max_depth=4, n_estimators=300, score=0.7313674648840671, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed:   24.0s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=300 ...................................\n",
      "[CV]  max_depth=4, n_estimators=300, score=0.8029945579993426, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:   24.6s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=300 ...................................\n",
      "[CV]  max_depth=4, n_estimators=300, score=0.7765416902790965, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:   25.3s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=300 ...................................\n",
      "[CV]  max_depth=4, n_estimators=300, score=-0.09956477695488153, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   25.9s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=500 ...................................\n",
      "[CV]  max_depth=4, n_estimators=500, score=0.8495718718798169, total=   1.0s\n",
      "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed:   26.9s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=500 ...................................\n",
      "[CV]  max_depth=4, n_estimators=500, score=0.8313276245875515, total=   1.0s\n",
      "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:   27.9s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=500 ...................................\n",
      "[CV]  max_depth=4, n_estimators=500, score=0.8510926704412475, total=   1.0s\n",
      "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed:   28.9s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=500 ...................................\n",
      "[CV]  max_depth=4, n_estimators=500, score=0.8086461365090396, total=   1.0s\n",
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:   29.9s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=500 ...................................\n",
      "[CV]  max_depth=4, n_estimators=500, score=0.22964897090675918, total=   1.0s\n",
      "[Parallel(n_jobs=1)]: Done  55 out of  55 | elapsed:   30.9s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=700 ...................................\n",
      "[CV]  max_depth=4, n_estimators=700, score=0.8626146332807106, total=   1.2s\n",
      "[Parallel(n_jobs=1)]: Done  56 out of  56 | elapsed:   32.2s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=700 ...................................\n",
      "[CV]  max_depth=4, n_estimators=700, score=0.8580209281854542, total=   1.4s\n",
      "[Parallel(n_jobs=1)]: Done  57 out of  57 | elapsed:   33.6s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=700 ...................................\n",
      "[CV]  max_depth=4, n_estimators=700, score=0.8566494603403749, total=   1.4s\n",
      "[Parallel(n_jobs=1)]: Done  58 out of  58 | elapsed:   34.9s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=700 ...................................\n",
      "[CV]  max_depth=4, n_estimators=700, score=0.7982105611789645, total=   1.3s\n",
      "[Parallel(n_jobs=1)]: Done  59 out of  59 | elapsed:   36.2s remaining:    0.0s\n",
      "[CV] max_depth=4, n_estimators=700 ...................................\n",
      "[CV]  max_depth=4, n_estimators=700, score=0.3566678054684468, total=   1.4s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   37.7s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=100 ...................................\n",
      "[CV]  max_depth=5, n_estimators=100, score=0.09797965405253294, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  61 out of  61 | elapsed:   37.9s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=100 ...................................\n",
      "[CV]  max_depth=5, n_estimators=100, score=0.19602929434458938, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  62 out of  62 | elapsed:   38.2s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=100 ...................................\n",
      "[CV]  max_depth=5, n_estimators=100, score=0.47118946927742045, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:   38.4s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=100 ...................................\n",
      "[CV]  max_depth=5, n_estimators=100, score=0.5092939310112469, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:   38.6s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=100 ...................................\n",
      "[CV]  max_depth=5, n_estimators=100, score=-1.3567888649490687, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:   38.9s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=300 ...................................\n",
      "[CV]  max_depth=5, n_estimators=300, score=0.7460815743936331, total=   0.7s\n",
      "[Parallel(n_jobs=1)]: Done  66 out of  66 | elapsed:   39.5s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=300 ...................................\n",
      "[CV]  max_depth=5, n_estimators=300, score=0.7311549283794919, total=   0.7s\n",
      "[Parallel(n_jobs=1)]: Done  67 out of  67 | elapsed:   40.2s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=300 ...................................\n",
      "[CV]  max_depth=5, n_estimators=300, score=0.801862868897021, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  68 out of  68 | elapsed:   40.8s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=300 ...................................\n",
      "[CV]  max_depth=5, n_estimators=300, score=0.7767621420867109, total=   0.7s\n",
      "[Parallel(n_jobs=1)]: Done  69 out of  69 | elapsed:   41.5s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=300 ...................................\n",
      "[CV]  max_depth=5, n_estimators=300, score=-0.09760211196086721, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:   42.1s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=500 ...................................\n",
      "[CV]  max_depth=5, n_estimators=500, score=0.8471221214941714, total=   1.1s\n",
      "[Parallel(n_jobs=1)]: Done  71 out of  71 | elapsed:   43.2s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=500 ...................................\n",
      "[CV]  max_depth=5, n_estimators=500, score=0.8362398346694884, total=   1.0s\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:   44.2s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=500 ...................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=5, n_estimators=500, score=0.8493488605760787, total=   1.0s\n",
      "[Parallel(n_jobs=1)]: Done  73 out of  73 | elapsed:   45.3s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=500 ...................................\n",
      "[CV]  max_depth=5, n_estimators=500, score=0.8107553709503178, total=   1.0s\n",
      "[Parallel(n_jobs=1)]: Done  74 out of  74 | elapsed:   46.3s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=500 ...................................\n",
      "[CV]  max_depth=5, n_estimators=500, score=0.22775060017807858, total=   1.1s\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:   47.4s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=700 ...................................\n",
      "[CV]  max_depth=5, n_estimators=700, score=0.8604039505313364, total=   1.3s\n",
      "[Parallel(n_jobs=1)]: Done  76 out of  76 | elapsed:   48.8s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=700 ...................................\n",
      "[CV]  max_depth=5, n_estimators=700, score=0.8580315151786939, total=   1.4s\n",
      "[Parallel(n_jobs=1)]: Done  77 out of  77 | elapsed:   50.2s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=700 ...................................\n",
      "[CV]  max_depth=5, n_estimators=700, score=0.8559644910719502, total=   1.3s\n",
      "[Parallel(n_jobs=1)]: Done  78 out of  78 | elapsed:   51.6s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=700 ...................................\n",
      "[CV]  max_depth=5, n_estimators=700, score=0.8038694704396891, total=   1.4s\n",
      "[Parallel(n_jobs=1)]: Done  79 out of  79 | elapsed:   53.0s remaining:    0.0s\n",
      "[CV] max_depth=5, n_estimators=700 ...................................\n",
      "[CV]  max_depth=5, n_estimators=700, score=0.3622353984271312, total=   1.3s\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:   54.3s remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=100 ...................................\n",
      "[CV]  max_depth=6, n_estimators=100, score=0.09797965405253294, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed:   54.5s remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=100 ...................................\n",
      "[CV]  max_depth=6, n_estimators=100, score=0.19602929434458938, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  82 out of  82 | elapsed:   54.8s remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=100 ...................................\n",
      "[CV]  max_depth=6, n_estimators=100, score=0.47118946927742045, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  83 out of  83 | elapsed:   55.0s remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=100 ...................................\n",
      "[CV]  max_depth=6, n_estimators=100, score=0.5092939310112469, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  84 out of  84 | elapsed:   55.2s remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=100 ...................................\n",
      "[CV]  max_depth=6, n_estimators=100, score=-1.3567888649490687, total=   0.2s\n",
      "[Parallel(n_jobs=1)]: Done  85 out of  85 | elapsed:   55.4s remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=300 ...................................\n",
      "[CV]  max_depth=6, n_estimators=300, score=0.7460822278140304, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  86 out of  86 | elapsed:   56.1s remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=300 ...................................\n",
      "[CV]  max_depth=6, n_estimators=300, score=0.7306130493382256, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  87 out of  87 | elapsed:   56.6s remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=300 ...................................\n",
      "[CV]  max_depth=6, n_estimators=300, score=0.8012315453589773, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  88 out of  88 | elapsed:   57.3s remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=300 ...................................\n",
      "[CV]  max_depth=6, n_estimators=300, score=0.7764732335186295, total=   0.7s\n",
      "[Parallel(n_jobs=1)]: Done  89 out of  89 | elapsed:   58.0s remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=300 ...................................\n",
      "[CV]  max_depth=6, n_estimators=300, score=-0.09873732016473102, total=   0.6s\n",
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:   58.6s remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=500 ...................................\n",
      "[CV]  max_depth=6, n_estimators=500, score=0.8471237788516525, total=   1.1s\n",
      "[Parallel(n_jobs=1)]: Done  91 out of  91 | elapsed:   59.7s remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=500 ...................................\n",
      "[CV]  max_depth=6, n_estimators=500, score=0.8384255656298736, total=   1.1s\n",
      "[Parallel(n_jobs=1)]: Done  92 out of  92 | elapsed:  1.0min remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=500 ...................................\n",
      "[CV]  max_depth=6, n_estimators=500, score=0.8486297951228169, total=   1.0s\n",
      "[Parallel(n_jobs=1)]: Done  93 out of  93 | elapsed:  1.0min remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=500 ...................................\n",
      "[CV]  max_depth=6, n_estimators=500, score=0.8118566749672324, total=   1.0s\n",
      "[Parallel(n_jobs=1)]: Done  94 out of  94 | elapsed:  1.0min remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=500 ...................................\n",
      "[CV]  max_depth=6, n_estimators=500, score=0.23017184974878446, total=   1.0s\n",
      "[Parallel(n_jobs=1)]: Done  95 out of  95 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=700 ...................................\n",
      "[CV]  max_depth=6, n_estimators=700, score=0.8593226707139889, total=   1.5s\n",
      "[Parallel(n_jobs=1)]: Done  96 out of  96 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=700 ...................................\n",
      "[CV]  max_depth=6, n_estimators=700, score=0.8585541295234775, total=   1.5s\n",
      "[Parallel(n_jobs=1)]: Done  97 out of  97 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=700 ...................................\n",
      "[CV]  max_depth=6, n_estimators=700, score=0.8552500060634214, total=   1.4s\n",
      "[Parallel(n_jobs=1)]: Done  98 out of  98 | elapsed:  1.1min remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=700 ...................................\n",
      "[CV]  max_depth=6, n_estimators=700, score=0.8043770387706675, total=   2.0s\n",
      "[Parallel(n_jobs=1)]: Done  99 out of  99 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] max_depth=6, n_estimators=700 ...................................\n",
      "[CV]  max_depth=6, n_estimators=700, score=0.36596308322814447, total=   1.5s\n",
      "[CV] max_depth=7, n_estimators=100 ...................................\n",
      "[CV]  max_depth=7, n_estimators=100, score=0.09797965405253294, total=   0.2s\n",
      "[CV] max_depth=7, n_estimators=100 ...................................\n",
      "[CV]  max_depth=7, n_estimators=100, score=0.19602929434458938, total=   0.2s\n",
      "[CV] max_depth=7, n_estimators=100 ...................................\n",
      "[CV]  max_depth=7, n_estimators=100, score=0.47118946927742045, total=   0.2s\n",
      "[CV] max_depth=7, n_estimators=100 ...................................\n",
      "[CV]  max_depth=7, n_estimators=100, score=0.5092939310112469, total=   0.2s\n",
      "[CV] max_depth=7, n_estimators=100 ...................................\n",
      "[CV]  max_depth=7, n_estimators=100, score=-1.3567888649490687, total=   0.2s\n",
      "[CV] max_depth=7, n_estimators=300 ...................................\n",
      "[CV]  max_depth=7, n_estimators=300, score=0.7460822278140304, total=   0.6s\n",
      "[CV] max_depth=7, n_estimators=300 ...................................\n",
      "[CV]  max_depth=7, n_estimators=300, score=0.7306130493382256, total=   0.6s\n",
      "[CV] max_depth=7, n_estimators=300 ...................................\n",
      "[CV]  max_depth=7, n_estimators=300, score=0.8012315453589773, total=   0.7s\n",
      "[CV] max_depth=7, n_estimators=300 ...................................\n",
      "[CV]  max_depth=7, n_estimators=300, score=0.7764732335186295, total=   0.7s\n",
      "[CV] max_depth=7, n_estimators=300 ...................................\n",
      "[CV]  max_depth=7, n_estimators=300, score=-0.09873732016473102, total=   0.6s\n",
      "[CV] max_depth=7, n_estimators=500 ...................................\n",
      "[CV]  max_depth=7, n_estimators=500, score=0.8471203607866984, total=   1.1s\n",
      "[CV] max_depth=7, n_estimators=500 ...................................\n",
      "[CV]  max_depth=7, n_estimators=500, score=0.837696836185515, total=   1.1s\n",
      "[CV] max_depth=7, n_estimators=500 ...................................\n",
      "[CV]  max_depth=7, n_estimators=500, score=0.8491500653151822, total=   1.0s\n",
      "[CV] max_depth=7, n_estimators=500 ...................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=7, n_estimators=500, score=0.8116179774918789, total=   1.1s\n",
      "[CV] max_depth=7, n_estimators=500 ...................................\n",
      "[CV]  max_depth=7, n_estimators=500, score=0.23092476921205163, total=   1.1s\n",
      "[CV] max_depth=7, n_estimators=700 ...................................\n",
      "[CV]  max_depth=7, n_estimators=700, score=0.859033310763765, total=   1.4s\n",
      "[CV] max_depth=7, n_estimators=700 ...................................\n",
      "[CV]  max_depth=7, n_estimators=700, score=0.858247756968916, total=   1.4s\n",
      "[CV] max_depth=7, n_estimators=700 ...................................\n",
      "[CV]  max_depth=7, n_estimators=700, score=0.8557073428317006, total=   1.4s\n",
      "[CV] max_depth=7, n_estimators=700 ...................................\n",
      "[CV]  max_depth=7, n_estimators=700, score=0.8048931365918268, total=   1.4s\n",
      "[CV] max_depth=7, n_estimators=700 ...................................\n",
      "[CV]  max_depth=7, n_estimators=700, score=0.3635538978015697, total=   1.5s\n",
      "[CV] max_depth=8, n_estimators=100 ...................................\n",
      "[CV]  max_depth=8, n_estimators=100, score=0.09797965405253294, total=   0.2s\n",
      "[CV] max_depth=8, n_estimators=100 ...................................\n",
      "[CV]  max_depth=8, n_estimators=100, score=0.19602929434458938, total=   0.2s\n",
      "[CV] max_depth=8, n_estimators=100 ...................................\n",
      "[CV]  max_depth=8, n_estimators=100, score=0.47118946927742045, total=   0.2s\n",
      "[CV] max_depth=8, n_estimators=100 ...................................\n",
      "[CV]  max_depth=8, n_estimators=100, score=0.5092939310112469, total=   0.2s\n",
      "[CV] max_depth=8, n_estimators=100 ...................................\n",
      "[CV]  max_depth=8, n_estimators=100, score=-1.3567888649490687, total=   0.2s\n",
      "[CV] max_depth=8, n_estimators=300 ...................................\n",
      "[CV]  max_depth=8, n_estimators=300, score=0.7460822278140304, total=   0.6s\n",
      "[CV] max_depth=8, n_estimators=300 ...................................\n",
      "[CV]  max_depth=8, n_estimators=300, score=0.7306130493382256, total=   0.6s\n",
      "[CV] max_depth=8, n_estimators=300 ...................................\n",
      "[CV]  max_depth=8, n_estimators=300, score=0.8012315453589773, total=   0.6s\n",
      "[CV] max_depth=8, n_estimators=300 ...................................\n",
      "[CV]  max_depth=8, n_estimators=300, score=0.7764732335186295, total=   0.6s\n",
      "[CV] max_depth=8, n_estimators=300 ...................................\n",
      "[CV]  max_depth=8, n_estimators=300, score=-0.09873732016473102, total=   0.7s\n",
      "[CV] max_depth=8, n_estimators=500 ...................................\n",
      "[CV]  max_depth=8, n_estimators=500, score=0.8471724955877509, total=   1.1s\n",
      "[CV] max_depth=8, n_estimators=500 ...................................\n",
      "[CV]  max_depth=8, n_estimators=500, score=0.837696836185515, total=   1.0s\n",
      "[CV] max_depth=8, n_estimators=500 ...................................\n",
      "[CV]  max_depth=8, n_estimators=500, score=0.8491500653151822, total=   1.1s\n",
      "[CV] max_depth=8, n_estimators=500 ...................................\n",
      "[CV]  max_depth=8, n_estimators=500, score=0.8116179774918789, total=   1.0s\n",
      "[CV] max_depth=8, n_estimators=500 ...................................\n",
      "[CV]  max_depth=8, n_estimators=500, score=0.23092476921205163, total=   1.0s\n",
      "[CV] max_depth=8, n_estimators=700 ...................................\n",
      "[CV]  max_depth=8, n_estimators=700, score=0.8586480623807881, total=   1.6s\n",
      "[CV] max_depth=8, n_estimators=700 ...................................\n",
      "[CV]  max_depth=8, n_estimators=700, score=0.858247756968916, total=   1.4s\n",
      "[CV] max_depth=8, n_estimators=700 ...................................\n",
      "[CV]  max_depth=8, n_estimators=700, score=0.8557312380157465, total=   1.4s\n",
      "[CV] max_depth=8, n_estimators=700 ...................................\n",
      "[CV]  max_depth=8, n_estimators=700, score=0.8050169494732611, total=   1.4s\n",
      "[CV] max_depth=8, n_estimators=700 ...................................\n",
      "[CV]  max_depth=8, n_estimators=700, score=0.363860337276556, total=   1.4s\n",
      "[CV] max_depth=9, n_estimators=100 ...................................\n",
      "[CV]  max_depth=9, n_estimators=100, score=0.09797965405253294, total=   0.2s\n",
      "[CV] max_depth=9, n_estimators=100 ...................................\n",
      "[CV]  max_depth=9, n_estimators=100, score=0.19602929434458938, total=   0.2s\n",
      "[CV] max_depth=9, n_estimators=100 ...................................\n",
      "[CV]  max_depth=9, n_estimators=100, score=0.47118946927742045, total=   0.2s\n",
      "[CV] max_depth=9, n_estimators=100 ...................................\n",
      "[CV]  max_depth=9, n_estimators=100, score=0.5092939310112469, total=   0.2s\n",
      "[CV] max_depth=9, n_estimators=100 ...................................\n",
      "[CV]  max_depth=9, n_estimators=100, score=-1.3567888649490687, total=   0.2s\n",
      "[CV] max_depth=9, n_estimators=300 ...................................\n",
      "[CV]  max_depth=9, n_estimators=300, score=0.7460822278140304, total=   0.6s\n",
      "[CV] max_depth=9, n_estimators=300 ...................................\n",
      "[CV]  max_depth=9, n_estimators=300, score=0.7306130493382256, total=   0.7s\n",
      "[CV] max_depth=9, n_estimators=300 ...................................\n",
      "[CV]  max_depth=9, n_estimators=300, score=0.8012315453589773, total=   0.6s\n",
      "[CV] max_depth=9, n_estimators=300 ...................................\n",
      "[CV]  max_depth=9, n_estimators=300, score=0.7764732335186295, total=   0.7s\n",
      "[CV] max_depth=9, n_estimators=300 ...................................\n",
      "[CV]  max_depth=9, n_estimators=300, score=-0.09873732016473102, total=   0.8s\n",
      "[CV] max_depth=9, n_estimators=500 ...................................\n",
      "[CV]  max_depth=9, n_estimators=500, score=0.8471724955877509, total=   1.5s\n",
      "[CV] max_depth=9, n_estimators=500 ...................................\n",
      "[CV]  max_depth=9, n_estimators=500, score=0.837696836185515, total=   1.6s\n",
      "[CV] max_depth=9, n_estimators=500 ...................................\n",
      "[CV]  max_depth=9, n_estimators=500, score=0.8491500653151822, total=   1.3s\n",
      "[CV] max_depth=9, n_estimators=500 ...................................\n",
      "[CV]  max_depth=9, n_estimators=500, score=0.8116179774918789, total=   1.1s\n",
      "[CV] max_depth=9, n_estimators=500 ...................................\n",
      "[CV]  max_depth=9, n_estimators=500, score=0.23092476921205163, total=   1.1s\n",
      "[CV] max_depth=9, n_estimators=700 ...................................\n",
      "[CV]  max_depth=9, n_estimators=700, score=0.8586480623807881, total=   1.4s\n",
      "[CV] max_depth=9, n_estimators=700 ...................................\n",
      "[CV]  max_depth=9, n_estimators=700, score=0.858247756968916, total=   1.5s\n",
      "[CV] max_depth=9, n_estimators=700 ...................................\n",
      "[CV]  max_depth=9, n_estimators=700, score=0.8557312380157465, total=   1.5s\n",
      "[CV] max_depth=9, n_estimators=700 ...................................\n",
      "[CV]  max_depth=9, n_estimators=700, score=0.8050169494732611, total=   1.4s\n",
      "[CV] max_depth=9, n_estimators=700 ...................................\n",
      "[CV]  max_depth=9, n_estimators=700, score=0.363860337276556, total=   1.3s\n",
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1,\n",
       "       learning_rate=0.005, max_bin=25, max_depth=5, min_child_samples=10,\n",
       "       min_child_weight=5, min_split_gain=0, n_estimators=675, n_jobs=-1,\n",
       "       nthread=-1, num_leaves=10, objective=None, random_state=None,\n",
       "       reg_alpha=0, reg_lambda=0, seed=0, silent=True, subsample=0.995,\n",
       "       subsample_for_bin=50000, subsample_freq=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': range(2, 10), 'n_estimators': range(100, 800, 200)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'max_depth': range(2,10,1),\n",
    "              'n_estimators': range(100, 800, 200)}\n",
    "grid = GridSearchCV(model, parameters, cv=5, verbose=100)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'n_estimators': 700}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74226801, 0.83270431, 0.2544222 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor(boosting_type='gbdt', num_leaves=10, max_depth=6, learning_rate=0.005, n_estimators=700, max_bin=25, subsample_for_bin=50000, objective=None, min_split_gain=0, min_child_weight=5, min_child_samples=10, subsample=0.995, subsample_freq=1, colsample_bytree=1, reg_alpha=0, reg_lambda=0, seed=0, nthread=-1, silent=True)\n",
    "cross_val_score(model, X, y, cv=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
